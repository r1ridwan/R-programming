# it will show you all the existing data in R
data()
# Load Starward data
view(starwars)
# Load Starward data
view(starwars)
# it will show all the existing data in R
data()
# Load Starward data
data(starwars)
starwars
starwars
# Loading required package
library(tidyverse)
# Load Starward data
view(starwars)
starwars
data <- starwars
View(data)
View(hflights)
library(hflights)
View(hflights)
filter(hflights, DepTime < 500 | ArrTime > 2200)->flight5
View(flight5)
# Datasets
gapminder
# Load Gapminder Datasets:
library(gapminder)
# Datasets
gapminder
# Lets find each continent min population, maximum lifeExp, and average GdpPercap
gapminder %>%
group_by(continent) %>%
summarize(min_pop = min(pop),
max_lifeExp = max(lifeExp),
average_gdpPercap = mean(gdpPercap))
# Data Sorting
```
# Make up a randomly ordered vector
v = sample(101:110)
### Sort the vector
sort(v)
# Sort the vector
sort(v)
# Reverse sorting
sort(v, decreasing = TRUE)
df = data.frame(id = 1:4,
weight = c(20, 27, 24,22),
size = c("small", "large", "medium", "large"))
df
library(plyr)
install.packages("plyr")
library(plyr)
arrange(df, weight)
df[order(df$weight), ]
arrange(df, size, weight)
df
arrange(df, weight)
df[order(df$weight), ]
arrange(df, size, weight)
df[order(df$size, df$weight), ]
df[do.call(order, as.list(df)), ]
# Gapminder Datasets:
# it tracks economic and social indicators like life expectancy and the GDP per capital of countries over time
library(gapminder)
# Datasets
gapminder
# filter functions
gapminder %>%
filter(year == 2007)
gapminder %>%
filter(year == 2007 | year == 1952)
gapminder %>%
filter(country == "United States")
gapminder %>%
filter(country %in% c("Bangladesh", "Afghanistan"))
# Check available data
data()
airquality
head(airquality)
# check missing values
is.na(airquality)
sum(is.na(airquality))
# check duplicated rows
duplicated(airquality)
sum(duplicated(airquality))
# To find the position of duplicate elements in x, use this:
duplicated(x)
# Remove Duplicates
# Given the following vector:
x <- c(1, 1, 4, 5, 4, 6)
# To find the position of duplicate elements in x, use this:
duplicated(x)
# Extract duplicate elements:
x[duplicated(x)]
# remove duplicated elements
x[!duplicated(x)]
# Remove duplicates rows from a data frame based on a column values
# Load data
data <- as.tibble(iris)
duplicated(iris)
# Find the duplicated row number
which(duplicated(iris))
# Find the duplicated row number
which(duplicated(iris))
# Remove duplicates based on Sepal.Width columns
# ekhane 'speal.width' jei data gula duplicate hoise oi full row gula delete hoye jabe.
data = data[!duplicated(data$Sepal.Width), ]
unique(data)
data2 = unique(data)
# Load Gapminder Datasets:
library(gapminder)
# Datasets
gapminder
iris
# group_by functions
gapminder %>%
group_by(year) %>%
summarise(meanlifeExp = mean(lifeExp),
totalpop = sum(pop))
#average life expectancy and the total population in 2007 within each continent using group_by functions
gapminder %>%
filter(year == 2007)%>%
group_by(continent) %>%
summarise(meanlifeExp = mean(lifeExp),
totalpop = sum(pop))
# Find high population country in each continent 'top_n' function
gapminder %>%
group_by(continent) %>%
top_n(1, pop) %>%
arrange(desc(pop))
mydata2 <-iris
# Groupby function for dataframe in R
# Mean of Sepal.Length is grouped by Species variable.
summarise_at(group_by(mydata2,Species),vars(Sepal.Length),
funs(mean(.,na.rm=TRUE)))
swirl()
library(swirl)
swirl()
z <- c(1.1, 9, 3.14)
?c
z
c("z", "555")
c (z, 555, z)
z * 2 + 100
my_sqrt <- sqrt(z-1)
my_sqrt
my_div <- z / my_sqrt
# Install Pacakges
install.packages("rio")
# Load pacakges
library(rio)
install_formats()
# Import data
data <- import("data/gapminder.csv")
# Load pacakges
library(rio)
# Import data
data <- import("data/gapminder.csv")
library(tidyverse)
# Import data
data <- import("data/gapminder.csv")
# Import data
data <- import("data/gapminder.csv")
library(gapminder)
# Import data
data <- import("data/gapminder.csv")
gapminder
data <- gapminder
View(data)
# exploring data
# 1. examine first frew rows
head(data)
# exploring data
# 1. examine first frew rows
head(data)
head(data, 10)
head(data, n=10)
# examine last few rows
tail(data)
tail(data, 10)
tail(data, n = 10)
# 3. dimension
dim(data)
# 4. number of columns
ncol(data)
# 5. number of rows
nrow(data)
# 6. check data structure
glimpse(data)
# 7. check missing values
is.na(data)
sum(is.na(data))
# 8. check duplicated rows
duplicated(data)
sum(duplicated(data))
# 9. sampling
sample_n(data, 10)
sample_frac(data, 0.25)
# 1. select
# select single column by column name
select(data, country)
# select single column by column number
select(2)
# select single column by column number
select(data, 2)
View(data)
# select single column by column number
select(data, 1)
# select single column by column number
select(data, 2)
# select multiple columns by column mame
select(country, continent, year)
# select multiple columns by column mame
select(data, country, continent, year)
# select multiple columns by column number
select(data, 1:3)
select(dat, c(1, 2, 4))
select(data, c(1, 2, 4))
# remove single column by column name
select(data, -country)
# select single column by column number
select(data, -2)
# remove multiple columns by column name
select(data, -c(country, continent, year))
# select multiple columns by column number
select(data, -c(1, 2, 4))
names(data)
# select column by starts_with()
select(data, starts_with("c"))
# select column by ends_with()
select(data, ends_with("t"))
source("G:/CHIRAL R_For_Bioinforamtics_Training/Lecture 7.R", echo=TRUE)
# select column by ends_with()
select(data, ends_with("y"))
# select column by contains()
select(data, contains("l"))
# select column by contains()
select(data, contains("c"))
# select column by contains()
select(data, contains("e"))
select(data, contains("l"), contains("y"))
# 2. filter
filter(data, country == "Bangladesh")
names(data)
# Inequality("!=="
filter(data, country != "Bangladesh")
# Greater (">")
filter(data, gdpPercap > 800)
# less("<")
filter(data, gdpPercap < 800)
# greater or equal (">=")
filter(data, gdpPercap >= 800)
# less or equal ("<=")
filter(data, gdpPercap <= 800)
# Logical AND ("&"
filter(data, country == "Bangladesh" & gdpPercap >= 800)
# Logical OR ("|")
filter(data, country == "Bangladesh" | gdpPercap >= 800)
# Logical AND ("&"
filter(data, country == "Bangladesh" & gdpPercap >= 800)
# Logical OR ("|")
filter(data, country == "Bangladesh" | gdpPercap >= 800)
# the "%in%" operator
filter(data, country == "India")
filter(data, country %in% c("Bangladesh", "India", "Pakistan"))
# Select and Filter
select(data, country, gdpPercap)
# Select and Filter
subset_data <- select(data, country, gdpPercap)
View(subset_data)
filtered_data <- filter(subset_data, country == "Bangladesh" | gdpPercap >= 800)
View(filtered_data)
filtered_data <- filter(subset_data, country == "Bangladesh" & gdpPercap >= 800)
View(filtered_data)
View(subset_data)
View(filtered_data)
# chaining method ( |> ~ pipe operator)
data |>
select(country, gdpPercap) |>
filter(country == "Bangladesh" & gdpPercap >= 800)
# chaining method ( |> ~ pipe operator)
data |>
select(country, gdpPercap) %>%
filter(country == "Bangladesh" & gdpPercap >= 800)
# 3. arrange
data |>
arrange(pop) |>
head()
data |>
arrange(desc(pop)) |>
head()
# 4. mutate
data |>
mutate(gdp = gdpPercap * pop) |>
head()
# 5. group_by and summarise
data |>
group_by(continent) |>
summarise(mean(lifeExp))
# 5. group_by and summarise
data |>
group_by(continent) |>
summarise(mean_lifeExp = mean(lifeExp))
# 5. group_by and summarise
data |>
group_by(continent) |>
summarise(mean_lifeExp = mean(lifeExp),
median_lifeExp = median(lifeExp))
# 5. rename
data |>
rename(population = pop) |>
head()
# 4. mutate
data |>
mutate(gdp = gdpPercap * pop)  |>
head()
/ 10^10
# 4. mutate
data |>
mutate(gdp = gdpPercap * pop) / 10^10 |>
head()
# 4. mutate
data |>
mutate(gdp = gdpPercap * pop) / 10^10 |>
head()
# 4. mutate
data |>
mutate(gdp = gdpPercap * pop / 10^10) |>
head()
setwd("G:/CHIRAL R_For_Bioinforamtics_Training")
# 7. reshaping data
wide_data <- import("data/Life_Expectancy_Wide.xlsx")
setwd("G:/GIT/R-programming")
